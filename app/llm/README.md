# Sistema Inteligente de Gerenciamento de Modelos LLM

**Atualizado em:** 2025-11-06

## ğŸ“‹ VisÃ£o Geral

Sistema completo de gerenciamento de modelos LLM da OpenRouter com:
- âœ… AtualizaÃ§Ã£o automÃ¡tica diÃ¡ria dos modelos e preÃ§os
- âœ… Sistema de scoring para escolha do melhor modelo por tarefa
- âœ… Fallback inteligente em caso de falha
- âœ… CÃ¡lculo preciso de custos e estimativas
- âœ… 338 modelos disponÃ­veis (45 gratuitos)

## ğŸ—ï¸ Arquitetura

### Componentes Principais

```
app/llm/
â”œâ”€â”€ modelos_openrouter.json          # Base de dados de modelos (auto-atualizada)
â”œâ”€â”€ processar_modelos_openrouter.py  # Script de atualizaÃ§Ã£o dos modelos
â”œâ”€â”€ gerenciador_modelos.py           # Gerenciador centralizado
â”œâ”€â”€ chamador_llm_inteligente.py      # Sistema de fallback inteligente
â””â”€â”€ README.md                         # Esta documentaÃ§Ã£o

app/integracao/
â””â”€â”€ openrouter_api_v2.py             # Cliente OpenRouter melhorado
```

## ğŸ“Š Estrutura de Dados

### Arquivo `modelos_openrouter.json`

```json
{
  "metadata": {
    "ultima_atualizacao": "2025-11-06T13:26:28",
    "total_modelos": 338
  },
  "categorias": {
    "free": [...],           // 45 modelos gratuitos
    "ultra_economico": [...], // 290 modelos (<$0.0001/1K)
    "economico": [...],       // 2 modelos (<$0.0005/1K)
    "balanceado": [...]       // 1 modelo (<$0.002/1K)
  },
  "top_models": {
    "traducao": [...],        // Top 10 para traduÃ§Ã£o
    "analise": [...],         // Top 10 para anÃ¡lise
    "velocidade": [...],      // Top 10 mais rÃ¡pidos
    "custo_beneficio": [...]  // Top 10 custo-benefÃ­cio
  },
  "todos_modelos": [...]      // Lista completa
}
```

### Metadados de Cada Modelo

```json
{
  "id": "meta-llama/llama-3.1-70b-instruct:free",
  "name": "Meta: Llama 3.1 70B Instruct (free)",
  "description": "...",
  "context_length": 131072,
  "max_completion_tokens": 65536,
  "pricing": {
    "prompt": 0.0,
    "completion": 0.0,
    "total_per_1k": 0.0,
    "categoria": "free"
  },
  "scores": {
    "traducao": 10.0,         // 0.0-10.0
    "analise": 8.5,           // 0.0-10.0
    "velocidade": 5.0,        // 0.0-10.0
    "custo_beneficio": 10.0   // 0.0-10.0
  },
  "architecture": {...},
  "fallback_similar": [...]    // Modelos similares para fallback
}
```

## ğŸ¯ Sistema de Scoring

### Score de TraduÃ§Ã£o (0.0-10.0)
CritÃ©rios:
- Modelos conhecidos por qualidade multilÃ­ngue (+2.0)
- Context window grande (+1.5)
- Modelos 70B+ (+0.7)
- Palavra "instruct" no nome (+0.5)

**Top 5 Gratuitos:**
1. Mistral Small 3.1 24B - 10.0/10
2. Llama 3.3 70B Instruct - 10.0/10
3. Llama 3.2 3B Instruct - 10.0/10
4. Qwen2.5 72B Instruct - 10.0/10
5. Hermes 3 405B Instruct - 10.0/10

### Score de AnÃ¡lise (0.0-10.0)
CritÃ©rios:
- Modelos premium de raciocÃ­nio (+3.0)
- Termos "reasoning", "analysis" (+1.5)
- Context window >200K (+2.0)
- Modelos 405B+ (+1.5)

**Top 5 Custo-BenefÃ­cio:**
1. Amazon Nova Premier - 10.0/10 ($0.000015/1K)
2. Perplexity Sonar Pro - 10.0/10 ($0.000018/1K)
3. Mistral Voxtral Small - 10.0/10 (gratuito)
4. GPT-OSS Safeguard - 10.0/10 (gratuito)
5. Nemotron Nano 12B - 10.0/10 (gratuito)

### Score de Velocidade (0.0-10.0)
CritÃ©rios:
- Palavras "fast", "turbo", "flash" (+3.0)
- Modelos 7B-8B (+2.0)
- Providers rÃ¡pidos (Gemini Flash, GPT-4o-mini) (+2.0)

### Score de Custo-BenefÃ­cio (0.0-10.0)
FÃ³rmula: `(qualidade_mÃ©dia / preÃ§o_normalizado) * 10`
- Modelos gratuitos de qualidade tÃªm score mÃ¡ximo
- Modelos pagos sÃ£o avaliados por qualidade/preÃ§o

## ğŸš€ Uso

### 1. Gerenciador de Modelos

```python
from app.llm.gerenciador_modelos import obter_gerenciador

# Obter instÃ¢ncia
gerenciador = obter_gerenciador()

# Buscar modelo especÃ­fico
modelo = gerenciador.obter_modelo_por_id("meta-llama/llama-3.1-70b-instruct:free")

# Obter melhores para traduÃ§Ã£o (gratuitos)
melhores = gerenciador.obter_melhores_para_tarefa(
    tarefa="traducao",
    limite=5,
    categoria_preco="free"
)

# Obter modelos por faixa de preÃ§o
baratos = gerenciador.obter_modelos_por_faixa_preco(
    preco_max=0.0001,
    tarefa="analise",
    limite=10
)

# Obter fallbacks para um modelo
fallbacks = gerenciador.obter_fallback_para_modelo(
    model_id="anthropic/claude-3-sonnet",
    max_diferenca_preco=0.002,
    limite=5
)

# ForÃ§ar atualizaÃ§Ã£o dos modelos
gerenciador.forcar_atualizacao()
```

### 2. Chamador LLM Inteligente

```python
from app.llm.chamador_llm_inteligente import ChamadorLLMInteligente

# Criar chamador com fallback automÃ¡tico
async def meu_chamador_base(model_id: str, prompt: str, **kwargs):
    # Sua implementaÃ§Ã£o de chamada ao LLM
    pass

chamador = ChamadorLLMInteligente(
    chamador_base=meu_chamador_base,
    max_tentativas=3,  # Modelo principal + 2 fallbacks
    timeout_por_tentativa=30.0
)

# Chamar com fallback automÃ¡tico
resultado = await chamador.chamar_com_fallback(
    model_id="meta-llama/llama-3.1-70b-instruct:free",
    prompt="Traduza para portuguÃªs: Hello World",
    categoria_preco_max="free"
)

if resultado["sucesso"]:
    print(f"Resposta: {resultado['resposta']}")
    print(f"Modelo usado: {resultado['modelo_usado']}")
    print(f"Tentativas: {resultado['tentativas']}")
    print(f"Custo: ${resultado['custo_estimado']:.6f}")
else:
    print(f"Erro: {resultado['erro']}")

# Ou usar seleÃ§Ã£o automÃ¡tica do melhor modelo
resultado = await chamador.chamar_modelo_ideal(
    prompt="Analise este documento...",
    tarefa="analise",
    categoria_preco="balanceado"
)

# Obter mÃ©tricas
metricas = chamador.obter_metricas()
print(f"Taxa de sucesso: {metricas['taxa_sucesso']*100:.1f}%")
print(f"Custo total: ${metricas['custo_total_estimado_usd']:.6f}")
```

### 3. Cliente OpenRouter V2

```python
from app.integracao.openrouter_api_v2 import OpenRouterClientV2

async with OpenRouterClientV2() as client:
    # TraduÃ§Ã£o com fallback automÃ¡tico
    traducao = await client.traduzir_texto(
        texto="Innovation policy frameworks",
        idioma_destino="pt",
        categoria_preco="free"
    )

    # Detectar idioma
    idioma = await client.detectar_idioma("Este Ã© um texto em portuguÃªs")

    # Analisar fonte
    analise = await client.analisar_fonte(
        titulo="Policy Framework for Innovation",
        descricao="...",
        url="https://...",
        modo="balanceado"  # gratuito, balanceado, premium
    )

    # Estimativa de custos
    estimativa = client.obter_custos_estimados(
        num_traducoes=100,
        categoria_preco="free"
    )
    print(f"Custo estimado: R$ {estimativa['custo_brl']:.4f}")
    print(f"Tempo estimado: {estimativa['tempo_estimado_minutos']} min")

    # EstatÃ­sticas de uso
    stats = client.obter_estatisticas()
```

## ğŸ”„ AtualizaÃ§Ã£o AutomÃ¡tica

O sistema detecta automaticamente quando os dados estÃ£o desatualizados (>24h) e atualiza via API:

```python
# AtualizaÃ§Ã£o automÃ¡tica no prÃ³ximo carregamento
gerenciador = obter_gerenciador()  # Verifica e atualiza se necessÃ¡rio

# Ou forÃ§ar atualizaÃ§Ã£o imediata
gerenciador.forcar_atualizacao()
```

### Processo de AtualizaÃ§Ã£o

1. **Busca API OpenRouter** â†’ `/api/v1/models`
2. **Processa modelos** â†’ Adiciona scores e metadados
3. **Salva JSON** â†’ `modelos_openrouter.json`
4. **Atualiza cache** â†’ Cache em memÃ³ria por 1h

## ğŸ’° Categorias de PreÃ§o

| Categoria | Faixa de PreÃ§o | Quantidade | Uso Recomendado |
|-----------|----------------|------------|-----------------|
| **free** | $0.00 | 45 | TraduÃ§Ãµes em massa |
| **ultra_economico** | <$0.0001/1K | 290 | AnÃ¡lises simples |
| **economico** | <$0.0005/1K | 2 | AnÃ¡lises mÃ©dias |
| **balanceado** | <$0.002/1K | 1 | AnÃ¡lises complexas |
| **premium** | <$0.01/1K | 0 | NÃ£o disponÃ­vel |
| **ultra_premium** | >$0.01/1K | 0 | NÃ£o disponÃ­vel |

## ğŸ“ Exemplos de Uso Real

### Exemplo 1: TraduÃ§Ã£o em Lote

```python
from app.integracao.openrouter_api_v2 import OpenRouterClientV2

async def traduzir_lote(textos: list[str]):
    async with OpenRouterClientV2() as client:
        # Estimar custo primeiro
        estimativa = client.obter_custos_estimados(
            num_traducoes=len(textos),
            categoria_preco="free"
        )

        print(f"Custo: R$ {estimativa['custo_brl']:.4f}")
        print(f"Tempo: ~{estimativa['tempo_estimado_minutos']} min")

        # Confirmar e executar
        traducoes = []
        for texto in textos:
            traducao = await client.traduzir_texto(
                texto,
                categoria_preco="free"
            )
            traducoes.append(traducao)

        return traducoes
```

### Exemplo 2: AnÃ¡lise com Fallback Inteligente

```python
from app.llm.chamador_llm_inteligente import ChamadorLLMInteligente
from app.integracao.openrouter_api_v2 import OpenRouterClientV2

async def analisar_com_fallback(documentos: list[dict]):
    client = OpenRouterClientV2()
    chamador = ChamadorLLMInteligente(
        chamador_base=client._chamar_modelo_base,
        max_tentativas=3
    )

    resultados = []
    for doc in documentos:
        prompt = f"Analise: {doc['texto']}"

        resultado = await chamador.chamar_modelo_ideal(
            prompt=prompt,
            tarefa="analise",
            categoria_preco="economico"
        )

        if resultado["sucesso"]:
            resultados.append({
                "documento_id": doc["id"],
                "analise": resultado["resposta"],
                "modelo": resultado["modelo_usado"],
                "custo": resultado["custo_estimado"]
            })

    # MÃ©tricas finais
    metricas = chamador.obter_metricas()
    print(f"AnÃ¡lises: {metricas['total_sucesso']}/{metricas['total_chamadas']}")
    print(f"Fallbacks: {metricas['total_fallbacks']}")
    print(f"Custo total: R$ {metricas['custo_total_estimado_brl']:.2f}")

    return resultados
```

## ğŸ”§ ManutenÃ§Ã£o

### AtualizaÃ§Ã£o Manual

```bash
cd "app/llm"

# 1. Buscar modelos da API
curl -X GET "https://openrouter.ai/api/v1/models" \
  -H "Authorization: Bearer $OPENROUTER_API_KEY" \
  -o /tmp/openrouter_models_raw.json

# 2. Formatar JSON
python3 -m json.tool /tmp/openrouter_models_raw.json > /tmp/openrouter_models.json

# 3. Processar com metadados
python3 processar_modelos_openrouter.py \
  /tmp/openrouter_models.json \
  modelos_openrouter.json
```

### Verificar Status

```python
from app.llm.gerenciador_modelos import obter_gerenciador

gerenciador = obter_gerenciador()
stats = gerenciador.obter_estatisticas()

print(f"Total de modelos: {stats['total_modelos']}")
print(f"Ãšltima atualizaÃ§Ã£o: {stats['ultima_atualizacao']}")
print(f"DistribuiÃ§Ã£o por categoria: {stats['por_categoria']}")
print("\nTop 5 Custo-BenefÃ­cio:")
for modelo in stats['top_custo_beneficio']:
    print(f"  - {modelo['name']}: {modelo['score']}/10")
```

## ğŸ“ˆ BenefÃ­cios

### Antes (Sistema Antigo)
- âŒ Modelos hardcoded no cÃ³digo
- âŒ PreÃ§os desatualizados
- âŒ Fallback manual e limitado
- âŒ DifÃ­cil adicionar novos modelos
- âŒ Sem mÃ©tricas de uso

### Agora (Sistema Novo)
- âœ… 338 modelos disponÃ­veis automaticamente
- âœ… PreÃ§os sempre atualizados (diariamente)
- âœ… Fallback inteligente automÃ¡tico
- âœ… Scoring para escolha otimizada
- âœ… MÃ©tricas detalhadas de custo/uso
- âœ… FÃ¡cil migraÃ§Ã£o gradual

## ğŸ” SeguranÃ§a

- API keys armazenadas em `.env` (nÃ£o versionado)
- Cache local do JSON (nÃ£o versionado)
- Sem dados sensÃ­veis no repositÃ³rio
- Timeouts configurÃ¡veis para evitar custos excessivos

## ğŸ“ Notas Importantes

1. **Compatibilidade**: O sistema mantÃ©m compatibilidade com o cÃ³digo antigo. MigraÃ§Ã£o pode ser gradual.

2. **AtualizaÃ§Ã£o automÃ¡tica**: Ocorre automaticamente no primeiro uso apÃ³s 24h da Ãºltima atualizaÃ§Ã£o.

3. **Fallback**: Sistema tenta atÃ© 3 modelos automaticamente, respeitando faixa de preÃ§o.

4. **Scores**: Baseados em heurÃ­sticas e benchmarks conhecidos. Podem ser ajustados em `processar_modelos_openrouter.py`.

5. **Cache**: Gerenciador mantÃ©m cache em memÃ³ria por 1h para performance.

## ğŸ› Troubleshooting

### Erro: "Arquivo de modelos nÃ£o encontrado"
```bash
python3 app/llm/processar_modelos_openrouter.py
```

### Erro: "OPENROUTER_API_KEY nÃ£o encontrada"
Verifique arquivo `.env`:
```bash
OPENROUTER_API_KEY=sk-or-v1-...
```

### Modelos retornando erro 429 (Rate Limit)
Use modelos pagos ou aguarde reset do rate limit.

### AtualizaÃ§Ã£o automÃ¡tica nÃ£o funcionando
ForÃ§ar manualmente:
```python
gerenciador.forcar_atualizacao()
```

## ğŸ“š ReferÃªncias

- [OpenRouter API](https://openrouter.ai/docs)
- [DocumentaÃ§Ã£o de Modelos](https://openrouter.ai/models)
- [PreÃ§os Atualizados](https://openrouter.ai/models?pricing=true)

---

**Ãšltima atualizaÃ§Ã£o:** 2025-11-06
**VersÃ£o:** 1.0
**Autor:** Sistema Sebrae Nacional
